{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRP1 - Relation extraction",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72446e9f21794629b67f6a038dd1cedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c0e968a7e3e4a65a49cd4b93c7b16aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_82234dd015774d99a3858c237b8bd566",
              "IPY_MODEL_bd2820cc21e4425aae02ea4bc856a1cc",
              "IPY_MODEL_6eabdb4c28584ca38984c4d38846dfe5"
            ]
          }
        },
        "4c0e968a7e3e4a65a49cd4b93c7b16aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82234dd015774d99a3858c237b8bd566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_405a8638b85c437ab5fb5433494f1911",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_172d60f2ed5f41a9b7b071e197df3959"
          }
        },
        "bd2820cc21e4425aae02ea4bc856a1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_316697e1c77d47b6bbe3f630e2107a4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 24459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63dea8dd116a4d92ba12d049d56f87a8"
          }
        },
        "6eabdb4c28584ca38984c4d38846dfe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a73db01edd5145d998fd020a9049b78f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 142k/? [00:00&lt;00:00, 3.29MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b29823681f3412f89edc118b32a4165"
          }
        },
        "405a8638b85c437ab5fb5433494f1911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "172d60f2ed5f41a9b7b071e197df3959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "316697e1c77d47b6bbe3f630e2107a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63dea8dd116a4d92ba12d049d56f87a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a73db01edd5145d998fd020a9049b78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b29823681f3412f89edc118b32a4165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYHvHhjPJ23I"
      },
      "source": [
        "## RE using Stanza dependency parser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bADc7fFVZNI",
        "outputId": "51c717f7-cfbf-4794-cd79-23d05321243c"
      },
      "source": [
        "pip install stanza"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.3.0-py3-none-any.whl (432 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 184 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 235 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 245 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 307 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 358 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 368 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 419 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 430 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 432 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=82d1244a2311931dc93bc007ccc4aa13f54be68393f1b4cb3ad7865ddaf12a55\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-1.6.1 stanza-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503,
          "referenced_widgets": [
            "72446e9f21794629b67f6a038dd1cedb",
            "4c0e968a7e3e4a65a49cd4b93c7b16aa",
            "82234dd015774d99a3858c237b8bd566",
            "bd2820cc21e4425aae02ea4bc856a1cc",
            "6eabdb4c28584ca38984c4d38846dfe5",
            "405a8638b85c437ab5fb5433494f1911",
            "172d60f2ed5f41a9b7b071e197df3959",
            "316697e1c77d47b6bbe3f630e2107a4a",
            "63dea8dd116a4d92ba12d049d56f87a8",
            "a73db01edd5145d998fd020a9049b78f",
            "6b29823681f3412f89edc118b32a4165"
          ]
        },
        "id": "odC-pOn_VRv0",
        "outputId": "6cbd5ea6-d7be-4b6b-9477-106b92afa937"
      },
      "source": [
        "import stanza\n",
        "stanza.download('en')       # This downloads the English models for the neural pipeline\n",
        "nlp = stanza.Pipeline('en') # This sets up a default neural pipeline in English"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72446e9f21794629b67f6a038dd1cedb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-16 14:32:19 INFO: Downloading default packages for language: en (English)...\n",
            "2021-11-16 14:32:20 INFO: File exists: /root/stanza_resources/en/default.zip.\n",
            "2021-11-16 14:32:31 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2021-11-16 14:32:31 INFO: Loading these models for language: en (English):\n",
            "============================\n",
            "| Processor    | Package   |\n",
            "----------------------------\n",
            "| tokenize     | combined  |\n",
            "| pos          | combined  |\n",
            "| lemma        | combined  |\n",
            "| depparse     | combined  |\n",
            "| sentiment    | sstplus   |\n",
            "| constituency | wsj       |\n",
            "| ner          | ontonotes |\n",
            "============================\n",
            "\n",
            "2021-11-16 14:32:31 INFO: Use device: gpu\n",
            "2021-11-16 14:32:31 INFO: Loading: tokenize\n",
            "2021-11-16 14:33:31 INFO: Loading: pos\n",
            "2021-11-16 14:33:31 INFO: Loading: lemma\n",
            "2021-11-16 14:33:31 INFO: Loading: depparse\n",
            "2021-11-16 14:33:31 INFO: Loading: sentiment\n",
            "2021-11-16 14:33:32 INFO: Loading: constituency\n",
            "2021-11-16 14:33:33 INFO: Loading: ner\n",
            "2021-11-16 14:33:33 INFO: Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvBiX5lFWcio"
      },
      "source": [
        "sentence = \"Barack Obama was born in Hawaii. He was elected president in 2008.\"\n",
        "#sentence = \"In the summer of 2014 several discussions took place between the Muslim community of the municipality of Adigeni and the local government authorities on the status of an old building in the village of Mokhe (“the disputed building”), asserted by the former to be an ancient mosque.\"\n",
        "doc = nlp(sentence)\n",
        "# doc.sentences[0].print_dependencies()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ukCC-dWBTaV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrKnE3KKXGpN",
        "outputId": "ca4f92c5-b673-45b1-a3c1-6f6056bc0f04"
      },
      "source": [
        "# ner_tags = [\"PERS\", \"PERS\", \"O\", \"O\", \"O\", \"LOC\", \"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\",\"O\"]\n",
        "\n",
        "for sent in doc.sentences:\n",
        "  for word in sent.words:\n",
        "    # if (ner_tags[word.id] == \"PERS\" && )\n",
        "    print(word.id, word.text, word.head, sent.words[word.head-1].text, word.deprel)\n",
        "    # print(word.text, sent.words[sent.words[word.head-1].head-1].text, sent.words[word.head-1].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Barack 4 born nsubj:pass\n",
            "2 Obama 1 Barack flat\n",
            "3 was 4 born aux:pass\n",
            "4 born 0 . root\n",
            "5 in 6 Hawaii case\n",
            "6 Hawaii 4 born obl\n",
            "7 . 4 born punct\n",
            "1 He 3 elected nsubj:pass\n",
            "2 was 3 elected aux:pass\n",
            "3 elected 0 . root\n",
            "4 president 3 elected xcomp\n",
            "5 in 6 2008 case\n",
            "6 2008 3 elected obl\n",
            "7 . 3 elected punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epNzDbPpHb7b"
      },
      "source": [
        "def appendChunk(org, new):\n",
        "    return org + ' ' + new\n",
        "\n",
        "def isRelationCandidate(token):\n",
        "    deps = [\"root\", \"adj\", \"attr\", \"agent\"]\n",
        "    return any(subs in token.deprel for subs in deps)\n",
        "\n",
        "def isConstructionCandidate(token):\n",
        "    deps = [\"compound\", \"prep\", \"conj\", \"mod\", \"obl\"]\n",
        "    return any(subs in token.deprel for subs in deps)\n",
        "\n",
        "def processSubjectObjectPairs(tokens):\n",
        "    subject = ''\n",
        "    obj = ''\n",
        "    relation = ''\n",
        "    subjectConstruction = ''\n",
        "    objectConstruction = ''\n",
        "    for token in tokens:\n",
        "        #printToken(token)\n",
        "        if \"punct\" in token.deprel:\n",
        "            continue\n",
        "        if isRelationCandidate(token):\n",
        "            relation = appendChunk(relation, token.text)\n",
        "        if isConstructionCandidate(token):\n",
        "            if subjectConstruction:\n",
        "              subjectConstruction = appendChunk(subjectConstruction, token.text)\n",
        "            if objectConstruction:\n",
        "              objectConstruction = appendChunk(objectConstruction, token.text)\n",
        "        if \"subj\" in token.deprel:\n",
        "            subject = appendChunk(subject, token.text)\n",
        "            subject = appendChunk(subjectConstruction, subject)\n",
        "            subjectConstruction = ''\n",
        "        if \"obj\" in token.deprel:\n",
        "            obj = appendChunk(obj, token.text)\n",
        "            obj = appendChunk(objectConstruction, obj)\n",
        "            objectConstruction = ''\n",
        "\n",
        "    if obj == '':\n",
        "      obj = appendChunk(objectConstruction, obj)\n",
        "    if subject == '':\n",
        "      subject = appendChunk(subjectConstruction, subject)\n",
        "\n",
        "    print(subject.strip(), \",\", relation.strip(), \",\", obj.strip())\n",
        "    return (subject.strip(), relation.strip(), obj.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4shZ19oHkXs",
        "outputId": "6e02633d-ee5f-4d65-ad77-0abb5e417b75"
      },
      "source": [
        "## Could be improved by adding coreference and anaphore resolution (coref)\n",
        "for sent in doc.sentences:\n",
        "  processSubjectObjectPairs(sent.words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Barack , born , \n",
            "He , elected , \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PZrvfTBOugn"
      },
      "source": [
        "## Sensitive to exceptions\n",
        "## https://universaldependencies.org/u/dep/ (Look at Hawaï)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvrG33GoJ_Mw"
      },
      "source": [
        "## SpaCy RE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qplbYJ5oapYW",
        "outputId": "d12870e5-591b-476a-ecc2-4e3a9f11c164"
      },
      "source": [
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "\n",
        "def getSentences(text):\n",
        "    nlp = English()\n",
        "    nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "    #nlp.add_pipe('sentencizer')\n",
        "    document = nlp(text)\n",
        "    #print([type(sent.text) for sent in document.sents])\n",
        "    return [sent.text.strip() for sent in document.sents]\n",
        "\n",
        "def printToken(token):\n",
        "    print(token.text, \"->\", token.dep_)\n",
        "\n",
        "def appendChunk(original, chunk):\n",
        "    return original + ' ' + chunk\n",
        "\n",
        "def isRelationCandidate(token):\n",
        "    deps = [\"ROOT\", \"adj\", \"attr\", \"agent\", \"amod\"]\n",
        "    return any(subs in token.dep_ for subs in deps)\n",
        "\n",
        "def isConstructionCandidate(token):\n",
        "    deps = [\"compound\", \"prep\", \"conj\", \"mod\"]\n",
        "    return any(subs in token.dep_ for subs in deps)\n",
        "\n",
        "def processSubjectObjectPairs(tokens):\n",
        "    subject = ''\n",
        "    object = ''\n",
        "    relation = ''\n",
        "    subjectConstruction = ''\n",
        "    objectConstruction = ''\n",
        "    for token in tokens:\n",
        "        #printToken(token)\n",
        "        if \"punct\" in token.dep_:\n",
        "            continue\n",
        "        if isRelationCandidate(token):\n",
        "            relation = appendChunk(relation, token.lemma_)\n",
        "        if isConstructionCandidate(token):\n",
        "            if subjectConstruction:\n",
        "                subjectConstruction = appendChunk(subjectConstruction, token.text)\n",
        "            if objectConstruction:\n",
        "                objectConstruction = appendChunk(objectConstruction, token.text)\n",
        "        if \"subj\" in token.dep_:\n",
        "            subject = appendChunk(subject, token.text)\n",
        "            subject = appendChunk(subjectConstruction, subject)\n",
        "            subjectConstruction = ''\n",
        "        if \"obj\" in token.dep_:\n",
        "            object = appendChunk(object, token.text)\n",
        "            object = appendChunk(objectConstruction, object)\n",
        "            objectConstruction = ''\n",
        "\n",
        "    print (subject.strip(), \",\", relation.strip(), \",\", object.strip())\n",
        "    return (subject.strip(), relation.strip(), object.strip())\n",
        "\n",
        "def processSentence(sentence):\n",
        "    tokens = nlp_model(sentence)\n",
        "    return processSubjectObjectPairs(tokens)\n",
        "\n",
        "\n",
        "text = \"The Court reiterates that by virtue of the essential function the press fulfils in a democracy, Article 10 of the Convention affords journalists protection, subject to the proviso that they act in good faith in order to provide accurate and reliable information in accordance with the tenets of responsible journalism (see, among other authorities, Pentikäinen v. Finland [GC], no. 11882/10, § 90, ECHR 2015). In considering the “duties and responsibilities” of a journalist, the potential impact of the medium concerned is an important factor and it is commonly acknowledged that the audiovisual media have often a much more immediate and powerful effect than the print media. The audiovisual media have means of conveying through images meanings which the print media are not able to impart. At the same time, the methods of objective and balanced reporting may vary considerably, depending among other things on the media in question. It is not for this Court, nor for the national courts for that matter, to substitute their own views for those of the press as to what technique of reporting should be adopted by journalists. In this context the Court reiterates that Article 10 protects not only the substance of the ideas and information expressed, but also the form in which they are conveyed (see Jersild, cited above, §§ 31). The punishment of a journalist for assisting in the dissemination of statements made by another person in an interview would seriously hamper the contribution of the press to discussion of matters of public interest and should not be envisaged unless there are particularly strong reasons for doing so (ibid., § 35, and Thoma, cited above, § 62). A general requirement for journalists systematically and formally to distance themselves from the content of a quotation that might insult or provoke others or damage their reputation is not reconcilable with the press’s role of providing information on current events, opinions and ideas (see Thoma, cited above, § 64).\"\n",
        "# text = \"On 11 February 2014 the Broadcasting Council issued a new decision in which it again concluded that the applicant company had breached the Broadcasting and Retransmission Act and fined it EUR 500. It held that the applicant company’s freedom of expression was to be restricted on the grounds of the ban on promoting drug use provided for in section 19(1)e) of the Broadcasting and Retransmission Act, which pursued the legitimate aim of protecting public order. That ban reflected the public interest in not publishing information which amounted to a positive assessment of drug use. Given the objective (strict) liability nature of the administrative offence, what was decisive in the case at hand was not whether the applicant company had aimed to promote drug use, but whether the programme, in the light of its content and the manner of processing the information, had had a promotional character. In the Broadcasting Council’s opinion, such was the case since X.’s comments had disseminated the idea that marijuana had a positive influence; the journalist’s comments had downplayed and justified them as being common, which went beyond a simple statement of views and beyond reproducing information that had already been publicly available. In that way, the applicant company had significantly interfered with the legitimate interests in protecting public order, health and morals, while the lowest possible fine had restricted its freedom of expression to a very little extent, which had made the interference fully proportionate.\"\n",
        "\n",
        "sentences = getSentences(text)\n",
        "nlp_model = spacy.load('en_core_web_sm')\n",
        "\n",
        "triples = []\n",
        "print (text)\n",
        "for sentence in sentences:\n",
        "    triples.append(processSentence(sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Court reiterates that by virtue of the essential function the press fulfils in a democracy, Article 10 of the Convention affords journalists protection, subject to the proviso that they act in good faith in order to provide accurate and reliable information in accordance with the tenets of responsible journalism (see, among other authorities, Pentikäinen v. Finland [GC], no. 11882/10, § 90, ECHR 2015). In considering the “duties and responsibilities” of a journalist, the potential impact of the medium concerned is an important factor and it is commonly acknowledged that the audiovisual media have often a much more immediate and powerful effect than the print media. The audiovisual media have means of conveying through images meanings which the print media are not able to impart. At the same time, the methods of objective and balanced reporting may vary considerably, depending among other things on the media in question. It is not for this Court, nor for the national courts for that matter, to substitute their own views for those of the press as to what technique of reporting should be adopted by journalists. In this context the Court reiterates that Article 10 protects not only the substance of the ideas and information expressed, but also the form in which they are conveyed (see Jersild, cited above, §§ 31). The punishment of a journalist for assisting in the dissemination of statements made by another person in an interview would seriously hamper the contribution of the press to discussion of matters of public interest and should not be envisaged unless there are particularly strong reasons for doing so (ibid., § 35, and Thoma, cited above, § 62). A general requirement for journalists systematically and formally to distance themselves from the content of a quotation that might insult or provoke others or damage their reputation is not reconcilable with the press’s role of providing information on current events, opinions and ideas (see Thoma, cited above, § 64).\n",
            "Court Article they , reiterate essential subject good accurate responsible other , virtue function fulfils democracy protection proviso faith order information accordance tenets journalism authorities Finland\n",
            "11882/10 , ECHR , \n",
            "impact it media , potential be important factor audiovisual immediate , duties journalist medium effect media\n",
            "media media , audiovisual have , means meanings which\n",
            "methods , same objective vary other , time reporting things media question\n",
            "It technique , be national own by , Court courts matter views those press reporting journalists\n",
            "Article substance form they , reiterate , context ideas which Jersild\n",
            "punishment , by hamper public strong reason , journalist dissemination statements person interview contribution press discussion matters interest\n",
            "35 , cite , \n",
            "requirement that Thoma , general be role current , journalists themselves content quotation others reputation press information events\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jReHVu6rSe50"
      },
      "source": [
        "## Disadvantages of current approach\n",
        "\n",
        "* It doesn't always work, because it's rule based, especially on sentences that are written differently (e.g. legal documents).\n",
        "* Only takes semantics limited into account\n",
        "* Only one relation per sentence -> Long sentences messes up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4kdrpgIakwg"
      },
      "source": [
        "## NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ejE1U1o72y4",
        "outputId": "e7d18dae-71b4-4924-bff0-3c01fef49a47"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.sem import extract_rels, rtuple\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwBEpzaSea0P",
        "outputId": "373f6077-c8b8-463b-f9a0-d4ed1fb69a8a"
      },
      "source": [
        "## Tag the sentence\n",
        "sample = \"Barack Obama is born in Hawai\"\n",
        "\n",
        "sentences = nltk.sent_tokenize(sample)\n",
        "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
        "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
        "\n",
        "# Maybe try to train averaged_perceptron_tagger (CRF, used by nltk.pos_tag),\n",
        "# to increase quality\n",
        "\n",
        "print(tagged_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('Barack', 'NNP'), ('Obama', 'NNP'), ('is', 'VBZ'), ('born', 'VBN'), ('in', 'IN'), ('Hawai', 'NNP')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDDcU_Ehbulv"
      },
      "source": [
        "# Extract relations\n",
        "X = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n",
        "\n",
        "ents = [\"LOCATION\", \"ORGANIZATION\", \"PERSON\", \"DURATION\", \"DATE\",\n",
        "        \"CARDINAL\", \"PERCENT\", \"MONEY\", \"MEASURE\"]\n",
        "\n",
        "for sub_ent in ents:\n",
        "  for obj_ent in ents:\n",
        "    for i, sent in enumerate(tagged_sentences):\n",
        "      sent = nltk.ne_chunk(sent)\n",
        "      for rel in extract_rels(sub_ent, obj_ent, sent, corpus='ace', pattern=X):\n",
        "        print(nltk.sem.rtuple(rel))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54pPO3ASdfiv",
        "outputId": "df6aa636-dea7-4b4e-b2fb-828198c84e19"
      },
      "source": [
        "# Didn't find any relation in the sentence\n",
        "print(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON Barack/NNP)\n",
            "  (ORGANIZATION Obama/NNP)\n",
            "  is/VBZ\n",
            "  born/VBN\n",
            "  in/IN\n",
            "  (GPE Hawai/NNP))\n"
          ]
        }
      ]
    }
  ]
}